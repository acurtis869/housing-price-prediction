{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "romance-malawi",
   "metadata": {},
   "source": [
    "# Housing Price Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "purple-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import some libraries that we know we are going to need.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-hearts",
   "metadata": {},
   "source": [
    "## Step 1: Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "foster-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in full downloaded dataset\n",
    "housing = pd.read_csv(\"pp-complete.csv\", header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-military",
   "metadata": {},
   "source": [
    "The dataset is over 4GB, which makes computation time very long for this machine. To get around this problem, I am going to randomly sample from the data (without replacement) to obtain a new dataset with 100,000 rows. This is still a relatively large sample so it will still reflect the distribution of the data, without the need for using stratified sampling. A random state is going to be used to ensure the resulting dataset is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "detailed-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from the data and save it in a new variable \n",
    "housing_sample = housing.sample(n = 100000, replace = False, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-legislation",
   "metadata": {},
   "source": [
    "We now need to filter the data to only take the columns of interest. An array y is created to store the labels (which in this case is the house prices), and a data frame X is created to store the predictor variables (property type, estate type, location). The location column must also be transformed into a binary value indicating whether the property is in London."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acoustic-strength",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexcurtis/my_env/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Filter to only take columns of interest\n",
    "y = housing_sample[1]\n",
    "X = housing_sample[[4, 6, 11]]\n",
    "# Filter location to be a boolean for london/not london\n",
    "X[11] = np.where(X[11].str.contains(\"LONDON\"), 1, 0)\n",
    "# Add more meaningful column names\n",
    "y.columns = \"price\"\n",
    "X.columns = [\"property.type\", \"estate.type\", \"london\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-slovenia",
   "metadata": {},
   "source": [
    "Let's have a look at the first five rows of the data to see if it has been formatted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "precious-gambling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property.type</th>\n",
       "      <th>estate.type</th>\n",
       "      <th>london</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22470060</th>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22284178</th>\n",
       "      <td>D</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19668643</th>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632478</th>\n",
       "      <td>S</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10190356</th>\n",
       "      <td>D</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         property.type estate.type  london\n",
       "22470060             T           F       1\n",
       "22284178             D           F       0\n",
       "19668643             S           F       0\n",
       "3632478              S           L       0\n",
       "10190356             D           F       0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-journalist",
   "metadata": {},
   "source": [
    "Looks good! Now let's just make sure there aren't any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "exterior-surprise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any missing values\n",
    "X.isna().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-weekend",
   "metadata": {},
   "source": [
    "This confirms that there are no missing values so all good. \n",
    "We now need to transform our predictor data, X, so that the factors in the categorical variables are all binary values. This will be essential in fitting the models later on. We can do this using Scikit-Learn's OneHotEncoder class implemented in a column tranforming pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "special-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding to handle categorical variables\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Define which variables to transform\n",
    "cat_attribs = [\"property.type\", \"estate.type\"]\n",
    "\n",
    "# Create pipeline\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])\n",
    "\n",
    "# Transform data\n",
    "X = full_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-federal",
   "metadata": {},
   "source": [
    "We now need to split the data into training and testing data so we can evaluate the model later on. As instructed, we will do this by using pre-2017 data for training, and the rest for testing. To do this we can import datetime, and filter the data using datetime values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "pacific-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Transform date column in the original sample data to datetime values\n",
    "housing_sample[2] = pd.to_datetime(housing_sample[2])\n",
    "\n",
    "# Calculate where date is pre- or post-2017 and save the indices in an array\n",
    "index_train = (housing_sample[2] < datetime.datetime(2017, 1, 1))\n",
    "index_test = (housing_sample[2] >= datetime.datetime(2017, 1, 1))\n",
    "\n",
    "# Split the data using the inidices above\n",
    "y_train = y[index_train]\n",
    "y_test = y[index_test]\n",
    "X_train = X[index_train]\n",
    "X_test = X[index_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-affect",
   "metadata": {},
   "source": [
    "If we have split the data correctly, the lengths of the test plus the train data should equal the length of the original data. Check if this is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "innocent-anniversary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that this has been done correctly \n",
    "len(y) == len(y_train) + len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-recommendation",
   "metadata": {},
   "source": [
    "That means the data has been successfully split. Let's have a look at the ratio of test to train to ensure we have ample data for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "everyday-papua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16675222849675642"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test) / len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-player",
   "metadata": {},
   "source": [
    "This seems reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-archive",
   "metadata": {},
   "source": [
    "## Step 2: Exploratory Data Analysis\n",
    "There isn't much we can do here since all of the predictor data is categorical. We can still have a look at the distribution of the labels to see what we are trying to predict. We do this by creating a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "daily-essex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.5608e+04, 7.1000e+01, 1.6000e+01, 7.0000e+00, 2.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+00]),\n",
       " array([9.50000000e+01, 2.34788550e+06, 4.69567600e+06, 7.04346650e+06,\n",
       "        9.39125700e+06, 1.17390475e+07, 1.40868380e+07, 1.64346285e+07,\n",
       "        1.87824190e+07, 2.11302095e+07, 2.34780000e+07]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-restoration",
   "metadata": {},
   "source": [
    "There are clearly some very high values (around 20,000,000) that are causing the data to be heavily right-skewed. Although these values are large, there is no reason to believe they are anomalous so we cannot remove them on those grounds. This skew will be a problem when fitting the models so let's try transforming the data to see if we can get a more reasonable distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "regional-python",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.0000e+00, 1.0000e+00, 1.1000e+01, 3.0600e+02, 9.2010e+03,\n",
       "        4.4181e+04, 2.9750e+04, 2.1290e+03, 1.1400e+02, 1.3000e+01]),\n",
       " array([ 4.55387689,  5.79564664,  7.03741639,  8.27918614,  9.52095588,\n",
       "        10.76272563, 12.00449538, 13.24626513, 14.48803487, 15.72980462,\n",
       "        16.97157437]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try a log transform\n",
    "plt.hist(np.log(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-technique",
   "metadata": {},
   "source": [
    "That looks a lot better to fit models to. Let's now use log(price) to fit some models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-wheel",
   "metadata": {},
   "source": [
    "## Step 3: Explore Different Models\n",
    "\n",
    "Let's look at several different types of models for predicting log house sale prices. We can evalaute these models using cross-validation (with the negative mean squared error as our scoring function) to select a model class, which we can then fine-tune.\n",
    "\n",
    "### Model 1: Linear Regression\n",
    "\n",
    "The first type of model we will look at is linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "disabled-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create linear regression object\n",
    "lin_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-jamaica",
   "metadata": {},
   "source": [
    "Evaluate this model using 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "arranged-physics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7426422504631365"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Calculate cross-validation scores\n",
    "scores = cross_val_score(lin_reg, X_train, np.log(y_train),\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "# Square root the scores so they are on the same scale as the response\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "# Output the mean of the scores\n",
    "np.mean(rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-visit",
   "metadata": {},
   "source": [
    "### Model 2: Decision Tree Regressor\n",
    "We will now repeat the exact same process, this time, with a decision tree regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afraid-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Create decision tree object, and set random state to ensure results are reproducible\n",
    "tree_reg = DecisionTreeRegressor(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sophisticated-norman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7412977991361361"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate cross-validation scores\n",
    "tree_scores = cross_val_score(tree_reg, X_train, np.log(y_train),\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "# Square root the scores so they are on the same scale as the response\n",
    "tree_rmse_scores = np.sqrt(-tree_scores)\n",
    "# Output the mean of the scores\n",
    "np.mean(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-legislation",
   "metadata": {},
   "source": [
    "### Model 3: Random Forest Regressor\n",
    "The final model we will try will be a random forest regressor. This is an ensemble method which uses decision trees so we would expect it to produce a better result that the one above (although at greater computational cost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "rubber-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create random forest object, and set random state to ensure results are reproducible\n",
    "forest_reg = RandomForestRegressor(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "banner-honey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7412977954008283"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate cross-validation scores\n",
    "forest_scores = cross_val_score(forest_reg, X_train, np.log(y_train),\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "# Square root the scores so they are on the same scale as the response\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "# Output the mean of the scores\n",
    "np.mean(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-adolescent",
   "metadata": {},
   "source": [
    "The best model (i.e. the one with the lowest RMSE score) is the random forest regressor, so we will continue with that and fine-tune the parameters. Since there wasn't a big difference between this model and the decision tree model, we could also perhaps have gone with that since it saves on computation time. However, let's assume for now that computation time isn't an issue and continue with the random forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-kingston",
   "metadata": {},
   "source": [
    "## Step 4: Fine-tuning the model\n",
    "Let's now continue with the random forest regressor and fine-tune the hyperparameters to find the best model. We can do this using grid search, which can be implemented using Scikit-Learn's GridSearchCV class which searches for the hyperparameters that minimise the cross-validation score. Again, we will use the negative mean squared error as our scoring function, although now we will use only 5-fold cross-validation, otherwise the computation time is too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "nominated-meditation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [5, 10, 20, 30, 40]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [5, 10, 20, 30, 40]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a grid of hyperparamters to search over\n",
    "parameters = [{'n_estimators': [5, 10, 20, 30, 40], 'max_features': [2, 4, 6, 8]},\n",
    "              {'bootstrap': [False], 'n_estimators': [5, 10, 20, 30, 40], 'max_features': [2, 4, 6, 8]},]\n",
    "\n",
    "# Create random forest object, setting random state for reproducibilty\n",
    "forest_reg = RandomForestRegressor(random_state = 42)\n",
    "    \n",
    "# Create grid search object, with specified hyperparameters to search\n",
    "grid_search = GridSearchCV(forest_reg, parameters, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "    \n",
    "# Run the grid search algorithm with the training data\n",
    "grid_search.fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-source",
   "metadata": {},
   "source": [
    "We can now see what the optimal hyperparameters are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "brilliant-shell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False, 'max_features': 8, 'n_estimators': 40}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-artist",
   "metadata": {},
   "source": [
    "These hyperparameters are at the top of the specified range so let's do another search to see if we can further improve our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "informal-dependence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n",
       "             param_grid=[{'bootstrap': [False], 'max_features': [7, 8],\n",
       "                          'n_estimators': [38, 39, 40, 41, 42, 43]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a finer grid with larger hyperparameters to search over\n",
    "parameters = [{'bootstrap': [False], 'n_estimators': [38, 39, 40, 41, 42, 43], 'max_features': [7, 8]},]\n",
    "\n",
    "# Create grid search object\n",
    "grid_search = GridSearchCV(forest_reg, parameters, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "    \n",
    "# Run the grid search\n",
    "grid_search.fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-antigua",
   "metadata": {},
   "source": [
    "Again let's see what the optimal hyperparaters were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "unlike-statement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False, 'max_features': 8, 'n_estimators': 38}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-spirituality",
   "metadata": {},
   "source": [
    "Interestingly, the max_features optimum has gone down. This perhaps suggests there isn't much improvement to be had around these values and so the output values are somewhat volatile. Either way, we can continue with these hyperparamters to evaluate our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-omega",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate and Present the Model\n",
    "It is now time to evaluate the model using the test data. As we have been doing throughout the process, we will be using root mean squared error as the metric on which to evaluate the model. This is chosen as it is easy to compare on the scale of the prediction, so we can get meaningful results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "integrated-embassy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761307099058814"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create the model with the optimum hyperparameters\n",
    "best_model = RandomForestRegressor(random_state = 42, bootstrap = False, max_features = 8, n_estimators = 38)\n",
    "# Fit the model using the training data\n",
    "best_model.fit(X_train, np.log(y_train))\n",
    "    \n",
    "# Make predictions using the test data\n",
    "predictions = best_model.predict(X_test)\n",
    "    \n",
    "# Calculate the RMSE, by using the test data labels\n",
    "mse = mean_squared_error(np.log(y_test), predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-rabbit",
   "metadata": {},
   "source": [
    "This is currently meaningless, since we have no scale with which to compare it to. The predictions were log(price), so let's calculate the mean of this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "activated-humanity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.821622701443603"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.log(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-grain",
   "metadata": {},
   "source": [
    "The mean of log(price) is over 11. That means the RMSE score of our model is pretty good. We can also calculate it as a fraction of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "grateful-alias",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07909549056437751"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse / np.mean(np.log(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-trick",
   "metadata": {},
   "source": [
    "The RMSE of the final model is less than 8% of the mean of the predictor values. That means it must have a pretty good predicitve power.\n",
    "\n",
    "We can also have a look at what features were most important for prediction in the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "distinguished-characterization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7448844054730149, 'london'),\n",
       " (0.1284416371095474, 'O'),\n",
       " (0.06442131831867201, 'T'),\n",
       " (0.026443714896735467, 'D'),\n",
       " (0.025742554692928292, 'S'),\n",
       " (0.009952849512996992, 'F'),\n",
       " (0.0, 'estate.type')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define which attributes to look at (i.e. 'london' and the one-hot encoded ones)\n",
    "extra_attribs = [\"london\", \"estate.type\"]\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = extra_attribs + cat_one_hot_attribs\n",
    "\n",
    "# Extract feature importances from the best model\n",
    "feature_importances = best_model.feature_importances_\n",
    "# Output the results in order of importance\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-experience",
   "metadata": {},
   "source": [
    "It looks like the 'london' binary variable was by far the most important predictor, at over 74%. The next best were the property type predictors (summing to roughly 25%), while estate type only contributed to less than 1%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
